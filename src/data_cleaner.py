import json
import os
import asyncio
import requests
from dotenv import load_dotenv
from tqdm.asyncio import tqdm

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# DeepSeek é…ç½®
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_URL = "https://api.deepseek.com/chat/completions"

# --- é…ç½®åŒº ---
CONCURRENCY_LIMIT = 50  # DeepSeek å¹¶è¡Œå¯ä»¥å¼€å¤§ç‚¹ï¼Œå»ºè®® 20-50
# --------------

class AsyncDataCleaner:
    def __init__(self):
        self.semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
        }

    async def summarize_visual_async(self, long_text):
        """
        å•ä¸ªä»»åŠ¡çš„å¼‚æ­¥åŒ…è£…
        """
        if not long_text or len(long_text) < 50:
            return long_text

        prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ¸…æ´—åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹è¿™æ®µå†—é•¿çš„è§†é¢‘ç”»é¢æè¿°ï¼Œç²¾ç®€ä¸ºã€ä¸€å¥è¯æ‘˜è¦ã€‘ã€‚
    
    è¦æ±‚ï¼š
    1. ä¿ç•™æ ¸å¿ƒåŠ¨ä½œï¼ˆå¦‚â€œåˆ‡è‚‰â€ã€â€œæ‹§èºä¸â€ï¼‰ã€‚
    2. ä¿ç•™å…³é”®ç‰©ä½“ï¼ˆå¦‚â€œèœåˆ€â€ã€â€œä¸‡ç”¨è¡¨â€ï¼‰ã€‚
    3. å»é™¤æ‰€æœ‰ä¿®é¥°æ€§åºŸè¯ã€‚
    4. å­—æ•°æ§åˆ¶åœ¨ 50 å­—ä»¥å†…ã€‚
    5. ç›´æ¥è¾“å‡ºæ‘˜è¦ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚

    å¾…å¤„ç†æ–‡æœ¬ï¼š
    {long_text}
    """

        async with self.semaphore:  # æ§åˆ¶å¹¶å‘æ•°
            payload = {
                "model": "deepseek-chat",
                "messages": [{
                    "role": "user", 
                    "content": prompt
                }],
                "temperature": 0.1,
                "max_tokens": 100
            }

            # ä½¿ç”¨ to_thread è®©åŒæ­¥çš„ requests ä¸å¡ä½å¼‚æ­¥å¾ªç¯
            try:
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(
                    None, 
                    lambda: requests.post(DEEPSEEK_URL, headers=self.headers, json=payload, timeout=20)
                )
                
                if response.status_code == 200:
                    return response.json()['choices'][0]['message']['content'].strip()
                else:
                    print(f"API é”™è¯¯: {response.status_code} - {response.text}")
                    return long_text
            except Exception as e:
                print(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
                return long_text

    async def process_file_async(self, input_path, output_path, category_tag):
        print(f"ğŸ“‚ æ­£åœ¨è¯»å–: {input_path}")
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"ğŸš€ å¼€å§‹å¼‚æ­¥æ¸…æ´— {len(data)} æ¡æ•°æ®...")
        
        # 1. å‡†å¤‡æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        tasks = []
        # ä¿å­˜åŸå§‹ item çš„å¼•ç”¨ï¼Œä»¥ä¾¿åç»­åˆå¹¶
        items_to_process = []
        
        for item in data:
            visual_context = item.get("visual_context", "")
            items_to_process.append(item)
            tasks.append(self.summarize_visual_async(visual_context))

        # 2. å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œå¹¶æ˜¾ç¤ºè¿›åº¦æ¡
        summaries = await tqdm.gather(*tasks, desc="API è¯·æ±‚è¿›åº¦")

        # 3. å°†ç»“æœæ‹¼å›åŸæ•°æ®
        cleaned_data = []
        for item, summary in zip(items_to_process, summaries):
            new_item = {
                "id": str(item['id']),
                "start": item['time_range'][0],
                "end": item['time_range'][1],
                "type": item['type'],
                "content": item['content'],
                "category": category_tag,
                "visual_summary": summary
            }

            # æ„é€  RAG æ–‡æœ¬
            rag_text = ""
            if new_item["visual_summary"]:
                rag_text += f"[ç”»é¢] {new_item['visual_summary']} "
            if new_item["content"]:
                rag_text += f"[è¯­éŸ³] {new_item['content']}"
            
            new_item["rag_text"] = rag_text.strip()
            cleaned_data.append(new_item)

        # 4. ä¿å­˜æ–‡ä»¶
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°: {output_path}")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        
        print("âœ… æ¸…æ´—å®Œæˆï¼")

def clean_json_data(input_path, output_path, category_tag="general"):
    """
    ä¸»å¤„ç†å‡½æ•° (å…¼å®¹æ—§æ¥å£ï¼Œå†…éƒ¨è°ƒç”¨å¼‚æ­¥å®ç°)
    """
    if not os.path.exists(input_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {input_path}")
        return

    cleaner = AsyncDataCleaner()
    asyncio.run(cleaner.process_file_async(input_path, output_path, category_tag))

if __name__ == "__main__":
    # é…ç½®ä½ çš„è·¯å¾„
    INPUT_FILE = "data/transcripts/raw_video_analysis.json" 
    OUTPUT_FILE = "data/transcripts/rag_ready_data.json"
    CATEGORY = "cooking" 

    clean_json_data(INPUT_FILE, OUTPUT_FILE, CATEGORY)
