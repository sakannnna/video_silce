import os
import sys
import subprocess
import numpy as np
import cv2
import json
from moviepy import VideoFileClip, concatenate_videoclips, CompositeVideoClip
import imageio_ffmpeg

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config import INPUT_VIDEO_DIR, OUTPUT_VIDEO_DIR
except ImportError:
    # å°è¯•ç›´æ¥å¯¼å…¥ï¼ˆé’ˆå¯¹ä¸åŒè¿è¡Œç¯å¢ƒçš„å…¼å®¹å¤„ç†ï¼‰
    try:
        import config
        INPUT_VIDEO_DIR = config.INPUT_VIDEO_DIR
        OUTPUT_VIDEO_DIR = config.OUTPUT_VIDEO_DIR
    except ImportError as e:
        print(f"Warning: Import failed: {e}")
        # è®¾ç½®é»˜è®¤è·¯å¾„
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        INPUT_VIDEO_DIR = os.path.join(base_dir, "data", "input_videos")
        OUTPUT_VIDEO_DIR = os.path.join(base_dir, "data", "output_videos")

class VideoProcessor:
    """è§†é¢‘å¤„ç†å™¨ï¼Œè´Ÿè´£æ ¹æ®åˆ†æç»“æœå‰ªè¾‘è§†é¢‘"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨"""
        pass

    def extract_audio(self, video_path, output_audio_path):
        """
        ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
        å‚æ•°Args:
            video_path: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_audio_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        è¿”å›Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"æ­£åœ¨æå–éŸ³é¢‘: {video_path} -> {output_audio_path}")
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_audio_path), exist_ok=True)
            
            with VideoFileClip(video_path) as video:
                audio = video.audio
                if audio is None:
                    print("Error: Video has no audio track.")
                    return False
                # å¼ºåˆ¶è½¬æ¢ä¸ºå•å£°é“ (ac=1) å’Œ 16000Hz (æˆ–è€…8000Hzï¼Œå–å†³äºæ¨¡å‹è¦æ±‚)
                # ç”¨æˆ·è¦æ±‚ä½¿ç”¨ 8k æ¨¡å‹ï¼Œå»ºè®®å°†é‡‡æ ·ç‡è®¾ä¸º 8000ï¼Œä½†é€šå¸¸ 16k ä¹Ÿå¯ä»¥ï¼ˆæ¨¡å‹ä¼šä¸‹é‡‡æ ·ï¼‰
                # ä¸ºäº†å®‰å…¨èµ·è§å’Œå‡å°‘æ•°æ®é‡ï¼Œè¿™é‡Œæˆ‘ä»¬é…åˆæ¨¡å‹è®¾ç½®ä¸º 8000ï¼Œå¹¶å¼ºåˆ¶å•å£°é“
                audio.write_audiofile(output_audio_path, logger=None, fps=8000, ffmpeg_params=["-ac", "1"])
            return True
        except Exception as e:
            print(f"æå–éŸ³é¢‘å¤±è´¥: {e}")
            return False

    def create_clip(self, video_path, start_time, end_time, output_path):
        """
        å‰ªè¾‘è§†é¢‘ç‰‡æ®µ
        å‚æ•°Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
            output_path: è¾“å‡ºè·¯å¾„
        è¿”å›Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            with VideoFileClip(video_path) as video:
                # è¾¹ç•Œæ£€æŸ¥
                if start_time < 0: start_time = 0
                if end_time > video.duration: end_time = video.duration
                if start_time >= end_time:
                    print(f"Invalid clip duration: {start_time}-{end_time}")
                    return False
                
                # MoviePy 2.0+ å…¼å®¹æ€§å¤„ç†
                if hasattr(video, 'subclipped'):
                     new_clip = video.subclipped(start_time, end_time)
                else:
                     new_clip = video.subclip(start_time, end_time)

                new_clip.write_videofile(
                    output_path, 
                    codec="libx264", 
                    audio_codec="aac", 
                    temp_audiofile='temp-audio.m4a', 
                    remove_temp=True,
                    logger=None
                )
            return True
        except Exception as e:
            print(f"å‰ªè¾‘ç‰‡æ®µå¤±è´¥: {e}")
            return False
    
    def select_key_clips(self, analyzed_segments, max_duration=300):
        pass

    def extract_keyframes(self, video_path, output_dir, interval=2.0):
        """
        [å·²å¼ƒç”¨] å»ºè®®ä½¿ç”¨ extract_smart_keyframes
        æ¯éš”ä¸€å®šæ—¶é—´æå–å…³é”®å¸§
        """
        return self.extract_smart_keyframes(video_path, output_dir)

    def extract_smart_keyframes(self, video_path, output_dir, max_gap=30):
        """
        æ™ºèƒ½æå–å…³é”®å¸§ï¼šåœºæ™¯æ£€æµ‹ + PPTæ£€æµ‹ + è¿åŠ¨æ£€æµ‹ + å…œåº•è¦†ç›–
        Args:
            video_path: è§†é¢‘è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            max_gap: å…œåº•ç­–ç•¥çš„æœ€å¤§æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        Returns:
            list: æå–çš„å…³é”®å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨ [{"time": float, "path": str}]
        """
        keyframes = []
        try:
            os.makedirs(output_dir, exist_ok=True)
            print(f"å¼€å§‹æ™ºèƒ½å…³é”®å¸§æå–: {video_path}")
            
            # 1. åœºæ™¯æ£€æµ‹
            print("  - [é˜¶æ®µ1] æ­£åœ¨è¿›è¡Œåœºæ™¯æ£€æµ‹...")
            scenes = self._detect_scenes_opencv(video_path)
            print(f"    æ£€æµ‹åˆ° {len(scenes)} ä¸ªåœºæ™¯")
            
            extracted_times = set()
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print("Error: Could not open video for reading.")
                return []
                
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0
            
            # å¤„ç†åœºæ™¯å¸§
            for scene in scenes:
                scene_start = scene['start_time']
                scene_end = scene['end_time']
                scene_duration = scene_end - scene_start
                
                # ä¸­é—´æˆªä¸€å¼ 
                mid_time = scene_start + scene_duration / 2
                self._add_keyframe(cap, mid_time, output_dir, keyframes, extracted_times)
                
                # é•¿åœºæ™¯é¢å¤–æˆªå–
                if scene_duration > 15:
                    self._add_keyframe(cap, scene_start + scene_duration/3, output_dir, keyframes, extracted_times)
                    self._add_keyframe(cap, scene_start + 2*scene_duration/3, output_dir, keyframes, extracted_times)

            # 2 & 3. æ£€æµ‹ PPT/æ–‡å­— å’Œ è¿åŠ¨æ£€æµ‹ (é‡‡æ ·æ£€æµ‹)
            print("  - [é˜¶æ®µ2&3] æ­£åœ¨æ£€æµ‹æ–‡å­—åŒºåŸŸ(OCRé¢„å¤„ç†)å’Œè¿åŠ¨å˜åŒ–...")
            # ä¸ºäº†æ•ˆç‡ï¼Œæ¯0.5ç§’é‡‡æ ·ä¸€å¸§
            sample_interval = 0.5 
            curr_time = 0.0
            
            prev_frame_gray = None
            last_motion_time = -100 # ä¸Šä¸€æ¬¡å› è¿åŠ¨æå–çš„æ—¶é—´
            
            while curr_time < duration:
                # è·³è¿‡å·²ç»æå–çš„æ—¶é—´ç‚¹é™„è¿‘ï¼Œä½†ä»éœ€è¯»å–å¸§ä»¥æ›´æ–° prev_frame
                is_extracted = False
                for t in extracted_times:
                    if abs(t - curr_time) < 0.2: # ç¨å¾®æ”¾å®½ä¸€ç‚¹
                        is_extracted = True
                        break
                
                cap.set(cv2.CAP_PROP_POS_MSEC, curr_time * 1000)
                ret, frame = cap.read()
                if not ret:
                    break
                    
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                
                # å¦‚æœå½“å‰æ—¶é—´ç‚¹å·²ç»è¢«æå–è¿‡ï¼Œåªæ›´æ–°prev_frameå¹¶ç»§ç»­
                if is_extracted:
                    prev_frame_gray = gray
                    curr_time += sample_interval
                    continue

                # A. PPT/æ–‡å­—æ£€æµ‹
                if self._detect_bright_rectangle(frame):
                    self._add_keyframe(cap, curr_time, output_dir, keyframes, extracted_times, prefix="ppt_")
                    last_motion_time = curr_time # PPTä¹Ÿç®—æ˜¯ä¸€ç§è§†è§‰å˜åŒ–ç‚¹
                
                # B. è¿åŠ¨æ£€æµ‹
                elif prev_frame_gray is not None:
                    # åªæœ‰å½“è·ç¦»ä¸Šæ¬¡è¿åŠ¨æå–è¶…è¿‡2ç§’æ—¶æ‰å†æ¬¡æå–ï¼Œé¿å…è¿ç»­è¿åŠ¨äº§ç”Ÿå¤§é‡å¸§
                    if curr_time - last_motion_time > 2.0:
                        if self._detect_motion_simple(prev_frame_gray, gray):
                            self._add_keyframe(cap, curr_time, output_dir, keyframes, extracted_times, prefix="motion_")
                            last_motion_time = curr_time

                prev_frame_gray = gray
                curr_time += sample_interval

            # 4. å…œåº•è¦†ç›–
            print("  - [å…œåº•] æ£€æŸ¥è¦†ç›–ç‡...")
            sorted_times = sorted(list(extracted_times))
            if not sorted_times:
                self._add_keyframe(cap, 0.0, output_dir, keyframes, extracted_times)
                sorted_times = [0.0]
            
            # æ£€æŸ¥å¼€å¤´
            if sorted_times[0] > max_gap:
                 self._add_keyframe(cap, 0.0, output_dir, keyframes, extracted_times)
            
            # æ£€æŸ¥ä¸­é—´ç©ºéš™
            sorted_times = sorted(list(extracted_times))
            for i in range(len(sorted_times) - 1):
                curr = sorted_times[i]
                next_t = sorted_times[i+1]
                if next_t - curr > max_gap:
                    fill_time = curr + (next_t - curr) / 2
                    self._add_keyframe(cap, fill_time, output_dir, keyframes, extracted_times, prefix="fill_")
            
            # æ£€æŸ¥ç»“å°¾
            if duration - sorted_times[-1] > max_gap:
                self._add_keyframe(cap, duration - 1.0, output_dir, keyframes, extracted_times)

            cap.release()
            
            # æŒ‰æ—¶é—´æ’åº
            keyframes.sort(key=lambda x: x['time'])
            return keyframes

        except Exception as e:
            print(f"æ™ºèƒ½æå–å…³é”®å¸§å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _add_keyframe(self, cap, time_sec, output_dir, keyframes_list, extracted_times_set, prefix="frame_"):
        """è¾…åŠ©å‡½æ•°ï¼šä¿å­˜å…³é”®å¸§"""
        # ç®€å•å»é‡
        for t in extracted_times_set:
            if abs(t - time_sec) < 0.2:
                return

        cap.set(cv2.CAP_PROP_POS_MSEC, time_sec * 1000)
        ret, frame = cap.read()
        if ret:
            frame_name = f"{prefix}{int(time_sec*1000):06d}.jpg"
            frame_path = os.path.join(output_dir, frame_name)
            cv2.imwrite(frame_path, frame)
            keyframes_list.append({"time": time_sec, "path": frame_path})
            extracted_times_set.add(time_sec)

    def _detect_scenes_opencv(self, video_path, threshold=0.7):
        """åœºæ™¯æ£€æµ‹ï¼šåŸºäºHSVç›´æ–¹å›¾"""
        scenes = []
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return []
            
        fps = cap.get(cv2.CAP_PROP_FPS)
        prev_hist = None
        scene_start_frame = 0
        curr_frame = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            if curr_frame % 5 != 0: # é™é‡‡æ ·
                curr_frame += 1
                continue
                
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            hist = cv2.calcHist([hsv], [0], None, [50], [0, 180])
            cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
            
            if prev_hist is not None:
                score = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)
                if score < threshold:
                    scenes.append({
                        "start_time": scene_start_frame / fps,
                        "end_time": curr_frame / fps
                    })
                    scene_start_frame = curr_frame
            
            prev_hist = hist
            curr_frame += 1
            
        # æœ€åä¸€ä¸ªåœºæ™¯
        total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
        if scene_start_frame < total_frames:
            scenes.append({
                "start_time": scene_start_frame / fps,
                "end_time": total_frames / fps
            })
            
        cap.release()
        return scenes

    def _detect_bright_rectangle(self, frame):
        """PPTæ£€æµ‹ï¼šæ£€æµ‹äº®è‰²çŸ©å½¢"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            height, width = frame.shape[:2]
            frame_area = width * height
            
            for cnt in contours:
                epsilon = 0.02 * cv2.arcLength(cnt, True)
                approx = cv2.approxPolyDP(cnt, epsilon, True)
                if len(approx) == 4:
                    area = cv2.contourArea(cnt)
                    if frame_area * 0.2 < area < frame_area * 0.95:
                        return True
            return False
        except Exception:
            return False

    def _detect_motion_simple(self, prev_gray, curr_gray, threshold=30):
        """è¿åŠ¨æ£€æµ‹ï¼šå¸§é—´å·®åˆ†"""
        try:
            diff = cv2.absdiff(prev_gray, curr_gray)
            # ç»Ÿè®¡å˜åŒ–è¶…è¿‡é˜ˆå€¼çš„åƒç´ æ¯”ä¾‹
            changed_ratio = np.sum(diff > threshold) / diff.size
            return changed_ratio > 0.05  # 5%çš„åƒç´ å‘ç”Ÿå˜åŒ–è§†ä¸ºæœ‰è¿åŠ¨
        except Exception:
            return False

    def select_key_clips(self, analyzed_segments, max_duration=300):
        """
        æ ¹æ®è¯„åˆ†é€‰æ‹©å…³é”®ç‰‡æ®µ
        """
        sorted_segments = sorted(analyzed_segments, key=lambda x: x.get('score', 0), reverse=True)
        selected_clips = []
        total_duration = 0
        for segment in sorted_segments:
            segment_duration = segment['end_time'] - segment['start_time']
            if segment_duration > 0 and total_duration + segment_duration <= max_duration:
                selected_clips.append(segment)
                total_duration += segment_duration
        selected_clips.sort(key=lambda x: x['start_time'])
        return selected_clips

    
    def combine_clips(self, clip_paths, output_filename="output_video.mp4"):
        """
        ç»„åˆç‰‡æ®µå¹¶ç”Ÿæˆæœ€ç»ˆè§†é¢‘
        å‚æ•°Args:
            clip_paths: è§†é¢‘ç‰‡æ®µè·¯å¾„åˆ—è¡¨ (æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†å…¼å®¹ main.pyï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ”¹ä¸ºè·¯å¾„åˆ—è¡¨)
            output_filename: è¾“å‡ºè§†é¢‘æ–‡ä»¶åæˆ–å®Œæ•´è·¯å¾„
        è¿”å›Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            clips = []
            # é€‚é…ï¼šå¦‚æœä¼ å…¥çš„æ˜¯è·¯å¾„åˆ—è¡¨ï¼ˆmain.py çš„è°ƒç”¨æ–¹å¼ï¼‰
            if isinstance(clip_paths, list) and all(isinstance(p, str) for p in clip_paths):
                 for path in clip_paths:
                     try:
                         clips.append(VideoFileClip(path))
                     except Exception as e:
                         print(f"Error loading clip {path}: {e}")
            else:
                 # ä¹‹å‰çš„é€»è¾‘æ˜¯ä¼ å…¥ video_path å’Œ segmentsï¼Œè¿™é‡Œä¸ºäº†å…¼å®¹ main.py åšäº†è°ƒæ•´
                 # å¦‚æœä½ éœ€è¦ä¿ç•™ä¹‹å‰çš„é€»è¾‘ï¼Œå¯ä»¥åŠ å‚æ•°åˆ¤æ–­ï¼Œä½† main.py ä¼ çš„æ˜¯ clip_paths
                 print("Error: combine_clips expects a list of file paths.")
                 return False

            if not clips:
                print("No valid clips to combine.")
                return False
            
            # ç»„åˆç‰‡æ®µ
            # ä½¿ç”¨ method="compose" å¯ä»¥é¿å…å› ä¸åŒç‰‡æ®µçš„å‚æ•°å¾®å°å·®å¼‚å¯¼è‡´çš„é—®é¢˜
            final_clip = concatenate_videoclips(clips, method="compose")
            
            # ç”Ÿæˆè¾“å‡ºè·¯å¾„
            # å¦‚æœ output_filename å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æ‹¼æ¥åˆ° OUTPUT_VIDEO_DIR
            if os.path.isabs(output_filename):
                output_path = output_filename
            else:
                output_path = os.path.join(OUTPUT_VIDEO_DIR, output_filename)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            # å¯¼å‡ºè§†é¢‘
            final_clip.write_videofile(
                output_path,
                codec="libx264",
                audio_codec="aac",
                fps=30,
                preset="medium",
                threads=4,
                logger=None
            )
            
            # å…³é—­èµ„æº
            for clip in clips:
                clip.close()
            final_clip.close()
            
            print(f"Video successfully generated: {output_path}")
            return True
            
        except Exception as e:
            print(f"Error processing video: {e}")
            return False
    
    def process_video(self, video_path, analyzed_segments, max_duration=300, output_filename="output_video.mp4"):
        """
        å®Œæ•´çš„è§†é¢‘å¤„ç†æµç¨‹ (ä¿ç•™æ­¤æ–¹æ³•ç”¨äºç‹¬ç«‹æµ‹è¯•ï¼Œä½† main.py ä¸è°ƒç”¨å®ƒ)
        """
        # é€‰æ‹©å…³é”®ç‰‡æ®µ
        selected_segments = self.select_key_clips(analyzed_segments, max_duration)
        
        if not selected_segments:
            print("No segments selected for processing.")
            return None
            
        # æ³¨æ„ï¼šè¿™é‡Œé€»è¾‘éœ€è¦è°ƒæ•´ï¼Œå› ä¸º combine_clips ç°åœ¨æ¥æ”¶æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        # å¦‚æœè¦ä¿ç•™ process_videoï¼Œéœ€è¦å…ˆè°ƒç”¨ create_clip ç”Ÿæˆä¸´æ—¶æ–‡ä»¶ï¼Œå† combine
        # ç®€å•èµ·è§ï¼Œè¿™é‡Œä»…æ‰“å°æç¤º
        print("process_video is deprecated in this version. Please use main.py workflow.")
        return None

    def convert_to_vertical(self, video_path, output_path=None, method="solid", background_color=(0, 0, 0)):
        """
        é«˜æ€§èƒ½æ¨ªå±è½¬ç«–å±ï¼ˆå®Œå…¨åŸºäºFFmpegåŸç”Ÿæ»¤é•œï¼‰
        """
        try:
            if output_path is None:
                video_name = os.path.splitext(os.path.basename(video_path))[0]
                output_path = os.path.join(os.path.dirname(video_path), f"{video_name}_vertical.mp4")

            # 1. è·å–è§†é¢‘åŸå§‹å°ºå¯¸
            # ä½¿ç”¨ MoviePy è¯»å–å°ºå¯¸ï¼Œé¿å…ç›´æ¥è°ƒç”¨ ffprobe
            try:
                clip = VideoFileClip(video_path)
                w, h = clip.size
                clip.close()
            except Exception as e:
                print(f"Error reading video dimensions with MoviePy: {e}")
                # Fallback to ffprobe if needed, but likely if MoviePy fails, ffprobe will too or it's not a video
                return False

            # è®¡ç®— 9:16 ç›®æ ‡å°ºå¯¸
            if w/h > 9/16: # æ¨ªå±
                target_h = h if h % 2 == 0 else h - 1
                target_w = int(target_h * 9 / 16)
                if target_w % 2 != 0: target_w -= 1
            else:
                print("è§†é¢‘å·²ç»æ˜¯ç«–å±æˆ–æ¯”ä¾‹æ¥è¿‘ï¼Œæ— éœ€è½¬æ¢")
                # å¦‚æœæ–‡ä»¶è·¯å¾„ä¸åŒï¼Œå¤åˆ¶ä¸€ä»½
                if output_path != video_path:
                    import shutil
                    shutil.copy2(video_path, output_path)
                return True

            print(f"ğŸš€ å¯åŠ¨ FFmpeg é«˜é€Ÿè½¬æ¢ | æ¨¡å¼: {method} | ç›®æ ‡: {target_w}x{target_h}")

            # 2. æ ¹æ®ä¸åŒæ¨¡å¼æ„å»ºä¸åŒçš„ FFmpeg æ»¤é•œå­—ç¬¦ä¸²
            if method == "solid":
                # çº¯è‰²èƒŒæ™¯ï¼šå…ˆç¼©æ”¾ä»¥é€‚åº”ç›®æ ‡å°ºå¯¸ï¼ˆä¿æŒæ¯”ä¾‹ï¼‰ï¼Œç„¶åå¡«å……
                # å°†RGBå…ƒç»„è½¬æ¢ä¸ºhexé¢œè‰²
                color_hex = "0x{:02x}{:02x}{:02x}".format(*background_color)
                # å…³é”®ä¿®æ­£ï¼šå¿…é¡»å…ˆ scale ç¼©å°è§†é¢‘ï¼Œå¦åˆ™ pad ä¼šæŠ¥é”™ï¼ˆå› ä¸ºè¾“å…¥å°ºå¯¸å¤§äºç›®æ ‡å°ºå¯¸ï¼‰
                filter_str = (
                    f"scale={target_w}:{target_h}:force_original_aspect_ratio=decrease,"
                    f"pad={target_w}:{target_h}:(ow-iw)/2:(oh-ih)/2:{color_hex}"
                )
            
            elif method == "blur":
                # æ¨¡ç³ŠèƒŒæ™¯ï¼š
                # [0:v] åˆ†ä¸ºä¸¤è·¯ï¼š
                # è·¯1(bg): ç¼©æ”¾å¹¶è£å‰ªå¡«å……æ•´ä¸ªç”»å¸ƒ -> é«˜æ–¯æ¨¡ç³Š
                # è·¯2(fg): ç¼©æ”¾ä»¥é€‚åº”ç”»å¸ƒå®½åº¦
                # æœ€åå°† fg è¦†ç›–åœ¨ bg ä¸­å¿ƒ
                filter_str = (
                    f"[0:v]scale={target_w}:{target_h}:force_original_aspect_ratio=increase,crop={target_w}:{target_h},boxblur=20:10[bg];"
                    f"[0:v]scale={target_w}:-1[fg];"
                    f"[bg][fg]overlay=(W-w)/2:(H-h)/2"
                )
            
            elif method == "static":
                # é™æ€èƒŒæ™¯ï¼ˆå–ç¬¬ä¸€å¸§ï¼‰ï¼š
                filter_str = (
                    f"[0:v]start_number=0,scale={target_w}:{target_h}:force_original_aspect_ratio=increase,crop={target_w}:{target_h},trim=end_frame=1,loop=-1:1[bg];"
                    f"[0:v]scale={target_w}:-1[fg];"
                    f"[bg][fg]overlay=(W-w)/2:(H-h)/2"
                )
            else:
                print(f"Unknown method: {method}, using solid black")
                filter_str = f"pad={target_w}:{target_h}:(ow-iw)/2:(oh-ih)/2:black"

            # 3. æ‰§è¡Œ FFmpeg å‘½ä»¤
            # å¢åŠ ç¡¬ä»¶åŠ é€Ÿå‚æ•°ï¼ˆå¦‚æœæœ‰Nvidiaæ˜¾å¡å¯ä»¥æ¢æˆ h264_nvencï¼‰
            # è·å– imageio æä¾›çš„ ffmpeg è·¯å¾„
            ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()
            
            cmd = [
                ffmpeg_exe, "-y",
                "-hide_banner",        # éšè—ç‰ˆæƒä¿¡æ¯
                "-i", video_path,
                "-vf", filter_str,
                "-c:v", "libx264",
                "-preset", "veryfast", # é€Ÿåº¦ä¼˜å…ˆ
                "-crf", "23",          # ç”»è´¨å¹³è¡¡
                "-c:a", "copy",        # éŸ³é¢‘ä¸é‡ç¼–ï¼Œç§’å®Œæˆ
                output_path
            ]

            subprocess.run(cmd, check=True)
            
            # éªŒè¯å¹¶è¿”å›
            self._force_file_sync(output_path)
            if self._verify_video_file_ready(output_path):
                print(f"âœ“ è½¬æ¢æˆåŠŸ: {output_path}")
                return True
            else:
                print(f"âŒ è½¬æ¢å¯èƒ½å¤±è´¥ï¼Œæ–‡ä»¶æœªå°±ç»ª: {output_path}")
                return False

        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _force_file_sync(self, filepath):
        """å¼ºåˆ¶åŒæ­¥æ–‡ä»¶åˆ°ç£ç›˜"""
        import os
        import sys
        
        try:
            # æ–¹æ³•1: Pythonæ–‡ä»¶åˆ·æ–°
            with open(filepath, 'ab') as f:
                f.flush()
                os.fsync(f.fileno())
            
            # æ–¹æ³•2: æ“ä½œç³»ç»Ÿçº§åŒæ­¥
            if sys.platform == 'win32':
                # Windowsç‰¹å®šå¤„ç†
                import ctypes
                kernel32 = ctypes.windll.kernel32
                handle = kernel32.CreateFileW(filepath, 0x40000000, 0, None, 3, 0, None)
                if handle != -1:
                    kernel32.FlushFileBuffers(handle)
                    kernel32.CloseHandle(handle)
            elif hasattr(os, 'sync'):
                # Unix/Linuxç³»ç»Ÿ
                os.sync()
                
        except Exception as e:
            print(f"æ–‡ä»¶åŒæ­¥è­¦å‘Š: {e}")

    def _verify_video_file_ready(self, filepath, timeout=10):
        """
        éªŒè¯è§†é¢‘æ–‡ä»¶æ˜¯å¦å®Œå…¨å¯è¯»
        """
        import time
        import os
        
        start_time = time.time()
        last_size = 0
        stable_count = 0
        
        while time.time() - start_time < timeout:
            try:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(filepath):
                    time.sleep(0.5)
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¨³å®š
                current_size = os.path.getsize(filepath)
                
                if current_size == last_size and current_size > 1024:  # å¤§äº1KB
                    stable_count += 1
                else:
                    stable_count = 0
                    last_size = current_size
                
                # å¦‚æœæ–‡ä»¶å¤§å°ç¨³å®š3æ¬¡æ£€æŸ¥
                if stable_count >= 3:
                    # å°è¯•è¯»å–æ–‡ä»¶å¤´ç¡®è®¤è§†é¢‘æ ¼å¼
                    with open(filepath, 'rb') as f:
                        header = f.read(100)
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶ï¼ˆMP4æ–‡ä»¶ä»¥"ftyp"å¼€å¤´ï¼‰
                        if header.startswith(b'\x00\x00\x00\x1cftyp'):
                            return True
                
                time.sleep(0.5)
                
            except (IOError, OSError, PermissionError) as e:
                time.sleep(1)
        
        # è¶…æ—¶åï¼Œå°è¯•æœ€åçš„ç®€å•æ£€æŸ¥
        try:
            if os.path.exists(filepath) and os.path.getsize(filepath) > 1024 * 1024:  # å¤§äº1MB
                return True
        except:
            pass
        
        return False

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    pass
